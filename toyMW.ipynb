{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 10:36:54.269507: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/hendrik/Documents/master_project/Code/LanguagePolicies/ros2/src/install/policy_translation/lib:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib::/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco200/bin\n",
      "2022-05-03 10:36:54.269524: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "from tests.metaworld.envs.mujoco.sawyer_xyz import utils\n",
    "sys.path.append('/home/hendrik/Documents/master_project/Code/LanguagePolicies/')\n",
    "from model_src.modelTorch import PolicyTranslationModelTorch\n",
    "from utils.Transformer import TailorTransformer\n",
    "from utils.networkMeta import NetworkMeta\n",
    "from utils.networkTorch import NetworkTorch\n",
    "import hashids\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from prettytable import PrettyTable\n",
    "import sys\n",
    "import pickle\n",
    "from utilsMW.model_setup import model_setup\n",
    "from utilsMW.dataLoaderMW import TorchDatasetMWToy\n",
    "from torch.utils.data import DataLoader\n",
    "from gym import logger\n",
    "from utilsMW.makeTrainingData import ToySimulation\n",
    "from searchTest.toyEnvironment import make_func, check_outpt, make_tol\n",
    "\n",
    "\n",
    "# Learning rate for the adam optimizer\n",
    "LEARNING_RATE   = 5e-6\n",
    "# Weight for the attention loss\n",
    "WEIGHT_ATTN     = 1.0\n",
    "# Weight for the motion primitive weight loss\n",
    "WEIGHT_W        = 1.0\n",
    "# Weight for the trajectroy generation loss\n",
    "WEIGHT_TRJ      = 1#5.0\n",
    "\n",
    "WEIGHT_GEN_TRJ  = 50\n",
    "\n",
    "# Weight for the time progression loss\n",
    "WEIGHT_DT       = 14.0\n",
    "# Weight for the phase prediction loss\n",
    "WEIGHT_PHS      = 1 #1.0\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "def setupModel(device , epochs ,  batch_size, path_dict , logname , model_path, tboard, model_setup, train_size = 1):\n",
    "    train_path = path_dict['META_WORLD'] + 'train/'\n",
    "    val_path = path_dict['META_WORLD'] + 'val/'\n",
    "    test_path = path_dict['META_WORLD'] + 'test/'\n",
    "    train_data = TorchDatasetMWToy(path=train_path, device=device)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_data = TorchDatasetMWToy(path=val_path, device=device)\n",
    "    eval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    test_data = TorchDatasetMWToy(path=test_path, device=device)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    env_tag = 'pickplace'\n",
    "    for inpt, outpt in train_loader:\n",
    "        dim_in = inpt.size(1)\n",
    "        dim_out = outpt.size(-1)\n",
    "        seq_len = outpt.size(1)\n",
    "        print(inpt.shape)\n",
    "        break\n",
    "    model_setup['plan_nn']['plan']['d_output'] = dim_out\n",
    "    model_setup['plan_nn']['plan']['seq_len'] = seq_len\n",
    "    model   = PolicyTranslationModelTorch(od_path=\"\", model_setup=model_setup, device=device).to(device)\n",
    "    for inpt, outpt in train_loader:\n",
    "        result = model(inpt)\n",
    "        break\n",
    "    tol_neg, tol_pos = make_tol(std_dev=5e-3, dim=dim_out, add=0.8, device='cuda')\n",
    "    successSimulation = ToySimulation(neg_tol=tol_neg, pos_tol=tol_pos, check_outpt_fct=check_outpt, dataloader=test_loader)\n",
    "\n",
    "    model_setup['tailor_transformer']['seq_len'] = seq_len\n",
    "    tailor_model = TailorTransformer(model_setup=model_setup['tailor_transformer'])\n",
    "    \n",
    "    \n",
    "    network = NetworkMeta(model, tailor_models=[tailor_model], env_tag=env_tag, successSimulation=successSimulation, data_path=path_dict['DATA_PATH'],logname=logname, lr=LEARNING_RATE, lw_atn=WEIGHT_ATTN, lw_w=WEIGHT_W, lw_trj=WEIGHT_TRJ, lw_gen_trj = WEIGHT_GEN_TRJ, lw_dt=WEIGHT_DT, lw_phs=WEIGHT_PHS, lw_fod=0, gamma_sl = 1, device=device, tboard=tboard)\n",
    "    network.setDatasets(train_loader=train_loader, val_loader=eval_loader)\n",
    "\n",
    "    network.setup_model(model_params=model_setup)\n",
    "    if model_path is not None:\n",
    "        model.load_state_dict(torch.load(model_path, map_location='cuda:0'))\n",
    "    count_parameters(network)\n",
    "    #print('in tailor transfo:')\n",
    "    #count_parameters(tailor_model)\n",
    "\n",
    "    network.train(epochs=epochs, model_params=model_setup)\n",
    "    return network\n",
    "\n",
    "import os\n",
    "\n",
    "logger.set_level(40)\n",
    "args = [\n",
    "    '-path', '/home/hendrik/Documents/master_project/LokalData/', '-batch_size', '32', '-train_size', '1', '-epochs', '1000', '-tboard', 'False'\n",
    "]\n",
    "if '-path' not in args:\n",
    "    print('no path given, not executing code')\n",
    "else:    \n",
    "    data_path = args[args.index('-path') + 1]\n",
    "    path_dict = {\n",
    "    'TRAIN_DATA_TORCH' : os.path.join(data_path, 'TorchDataset/train_data_torch.txt'),\n",
    "    'VAL_DATA_TORCH' : os.path.join(data_path, 'TorchDataset/val_data_torch.txt'),\n",
    "    'TRAIN_DATA' : os.path.join(data_path, 'GDrive/train.tfrecord'),\n",
    "    'VAL_DATA' : os.path.join(data_path, 'GDrive/validate.tfrecord'),\n",
    "    'GLOVE_PATH' : os.path.join(data_path, 'GDrive/glove.6B.50d.txt'),\n",
    "    'META_WORLD' : os.path.join(data_path, '/home/hendrik/Documents/master_project/LokalData/metaworld/test/toy_data/'),\n",
    "    'DATA_PATH' : data_path\n",
    "    }\n",
    "\n",
    "    device = 'cuda'\n",
    "    if '-device' in args:\n",
    "        device = args[args.index('-device') + 1]\n",
    "    from utilsMW.toy_model_setup import model_setup\n",
    "    model_path = None\n",
    "    if '-model' in args:\n",
    "        model_path = args[args.index('-model') + 1] + 'policy_translation_h'\n",
    "        if '-model_setup' in args:\n",
    "            setup_path = args[args.index('-model') + 1] + 'model_setup.pkl'\n",
    "            with open(setup_path, 'rb') as f:\n",
    "                model_setup = pickle.load(f)\n",
    "            model_setup['train']      = True\n",
    "            print('load model')\n",
    "    model_setup = model_setup\n",
    "    \n",
    "    epochs = 200\n",
    "    if '-epochs' in args:\n",
    "        epochs = int(args[args.index('-epochs') + 1])\n",
    "\n",
    "    batch_size = 16\n",
    "    if '-batch_size' in args:\n",
    "        batch_size = int(args[args.index('-batch_size') + 1])\n",
    "\n",
    "    tboard = True\n",
    "    if '-tboard' in args:\n",
    "        tboard = (args[args.index('-tboard') + 1]) == 'True'\n",
    "        print(f'tboard: {tboard}')\n",
    "\n",
    "    train_size = 1\n",
    "    if '-train_size' in args:\n",
    "        train_size = float(args[args.index('-train_size') + 1])\n",
    "\n",
    "    hid             = hashids.Hashids()\n",
    "    logname         = hid.encode(int(time.time() * 1000000))\n",
    "    print(f'logname: {logname}')\n",
    "    network = setupModel(device=device, epochs = epochs, batch_size = batch_size, path_dict = path_dict, logname=logname, model_path=model_path, tboard=tboard, model_setup=model_setup, train_size=train_size)\n",
    "    print(f'end saving: {path_dict[\"MODEL_PATH\"]}')\n",
    "    torch.save(network.state_dict(), path_dict['MODEL_PATH'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hendrik/Documents/master_project/Code/metaworld/toyMW.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/metaworld/toyMW.ipynb#ch0000001?line=63'>64</a>\u001b[0m loss \u001b[39m=\u001b[39m ((output\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m label_one_hot\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/metaworld/toyMW.ipynb#ch0000001?line=64'>65</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/metaworld/toyMW.ipynb#ch0000001?line=65'>66</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/metaworld/toyMW.ipynb#ch0000001?line=66'>67</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/metaworld/toyMW.ipynb#ch0000001?line=67'>68</a>\u001b[0m avrg_loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\n",
      "File \u001b[0;32m~/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "from tests.metaworld.envs.mujoco.sawyer_xyz import utils\n",
    "sys.path.append('/home/hendrik/Documents/master_project/Code/LanguagePolicies/')\n",
    "from model_src.modelTorch import PolicyTranslationModelTorch\n",
    "from utils.Transformer import TailorTransformer\n",
    "from utils.networkMeta import NetworkMeta\n",
    "from utils.networkTorch import NetworkTorch\n",
    "from utilsMW.dataLoaderMW import TorchDatasetTailor\n",
    "import hashids\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from prettytable import PrettyTable\n",
    "import sys\n",
    "import pickle\n",
    "from utilsMW.toy_model_setup import model_setup\n",
    "from utilsMW.dataLoaderMW import TorchDatasetMWToy\n",
    "from torch.utils.data import DataLoader\n",
    "from gym import logger\n",
    "from utilsMW.makeTrainingData import ToySimulation\n",
    "from searchTest.toyEnvironment import make_func, check_outpt, make_tol\n",
    "\n",
    "model_setup['tailor_transformer']\n",
    "tailor_model = TailorTransformer(model_setup=model_setup['tailor_transformer'])\n",
    "\n",
    "\n",
    "trajectories = torch.rand([10,1,1]).to('cuda')\n",
    "obsv = torch.rand([10,1,1]).to('cuda')\n",
    "success = torch.ones((10)).to('cuda')\n",
    "success[:2] = 0\n",
    "#success[1] = 0\n",
    "\n",
    "tailor_data = TorchDatasetTailor(trajectories= trajectories, obsv=obsv, success=success)\n",
    "tailor_loader = DataLoader(tailor_data, batch_size=2, shuffle=True)\n",
    "\n",
    "for outpt in tailor_loader:\n",
    "    succ, failed = outpt\n",
    "    s_trj, s_obs, success = succ\n",
    "    f_trj, f_obs, fail = failed\n",
    "    trajectories = torch.cat((s_trj, f_trj), dim=0)\n",
    "    inpt = torch.cat((s_obs, f_obs), dim=0)\n",
    "    label = torch.cat((success, fail), dim=0).type(torch.long)\n",
    "    label_one_hot = torch.nn.functional.one_hot(label, num_classes = 2)\n",
    "    inpt_super = torch.concat((trajectories, inpt), dim = -1)\n",
    "    output = tailor_model.forward(inpt_super)\n",
    "    break\n",
    "optimizer = torch.optim.Adam(tailor_model.parameters(), lr=1e-4)\n",
    "for i in range(10000):\n",
    "    avrg_loss = 0\n",
    "    for outpt in tailor_loader:\n",
    "        succ, failed = outpt\n",
    "        s_trj, s_obs, success = succ\n",
    "        f_trj, f_obs, fail = failed\n",
    "        trajectories = torch.cat((s_trj, f_trj), dim=0)\n",
    "        inpt = torch.cat((s_obs, f_obs), dim=0)\n",
    "        label = torch.cat((success, fail), dim=0).type(torch.long)\n",
    "        label_one_hot = torch.nn.functional.one_hot(label, num_classes = 2)\n",
    "        inpt_super = torch.concat((trajectories, inpt), dim = -1)\n",
    "        output = tailor_model.forward(inpt_super)\n",
    "        loss = ((output.reshape(-1) - label_one_hot.reshape(-1))**2).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avrg_loss+=loss\n",
    "    if i%100==0:\n",
    "        print(avrg_loss)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsMW.dataLoaderMW import TorchDatasetTailor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trajectories = torch.rand([10,1,1])\n",
    "obsv = torch.rand([10,1,1])\n",
    "success = torch.ones((10))\n",
    "success[0] = 0\n",
    "#success[1] = 0\n",
    "\n",
    "tailor_data = TorchDatasetTailor(trajectories= trajectories, obsv=obsv, success=success)\n",
    "tailor_loader = DataLoader(tailor_data, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9463]],\n",
       "\n",
       "        [[0.7719]],\n",
       "\n",
       "        [[0.7471]],\n",
       "\n",
       "        [[0.4551]],\n",
       "\n",
       "        [[0.5530]],\n",
       "\n",
       "        [[0.1816]],\n",
       "\n",
       "        [[0.1539]],\n",
       "\n",
       "        [[0.3654]],\n",
       "\n",
       "        [[0.7727]],\n",
       "\n",
       "        [[0.9233]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8743]],\n",
       "\n",
       "        [[0.0692]],\n",
       "\n",
       "        [[0.0792]],\n",
       "\n",
       "        [[0.3569]],\n",
       "\n",
       "        [[0.3110]],\n",
       "\n",
       "        [[0.7282]],\n",
       "\n",
       "        [[0.0724]],\n",
       "\n",
       "        [[0.7933]],\n",
       "\n",
       "        [[0.6466]],\n",
       "\n",
       "        [[0.5477]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "for outpt in tailor_loader:\n",
    "    succ, failed = outpt\n",
    "    s_trj, s_obs, success = succ\n",
    "    f_trj, f_obs, fail = failed\n",
    "    trajectories = torch.cat((s_trj, f_trj), dim=0)\n",
    "    inpt = torch.cat((s_obs, f_obs), dim=0)\n",
    "    label = torch.cat((success, fail), dim=0).type(torch.long)\n",
    "    label_one_hot = torch.nn.functional.one_hot(label, num_classes = 2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6edd83f9b3fcb9454c0e509bb1e55f01736f244b1bbba81ee1367549d9ea0fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mujoco')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
