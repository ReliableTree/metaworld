{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import gym\n",
    "from MetaWorld.searchTest.utils import MyEnv, ToyExpertModel, sample_expert_transitions, benchmark_policy, LearnWrapper, train_policy, SuperMyGymWrapper, supermipWrapper, LearnWrapper\n",
    "import torch\n",
    "import zipfile\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "import importlib\n",
    "import numpy as np\n",
    "from RlBaselines3Zoo import enjoy\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "from imitation.algorithms import bc\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "\n",
    "from stable_baselines3.common.policies import MultiInputActorCriticPolicy\n",
    "from stable_baselines3.common.torch_layers import (\n",
    "    BaseFeaturesExtractor,\n",
    "    CombinedExtractor,\n",
    "    FlattenExtractor,\n",
    "    NatureCNN,\n",
    "    create_mlp,\n",
    "    get_actor_critic_arch,\n",
    ")\n",
    "from sb3_contrib.tqc.tqc import TQC\n",
    "from sb3_contrib.tqc.policies import MultiInputPolicy\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "model = enjoy.main(inpt_args=\"--algo tqc --env FetchPickAndPlace-v1 --folder /home/hendrik/Documents/master_project/Code/RlBaselines3Zoo/rl-trained-agents -n 300 --ret_model True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TP_Wrapper(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def learn_fct(self, n_epochs):\n",
    "        self.learn(total_timesteps=n_epochs)\n",
    "\n",
    "class SAC_Wrapper(SAC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def learn_fct(self, n_epochs):\n",
    "        self.learn(total_timesteps=n_epochs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_policy = MultiInputActorCriticPolicy(observation_space=model.observation_space, action_space=model.action_space, lr_schedule=lambda a: 1, features_extractor_class=CombinedExtractor, net_arch=[512, 512, 512], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_env_wrapper = SuperMyGymWrapper(tag = None, bo=model.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_env = mon_env_wrapper.make_wrapper(count_resets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_env.reset_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_trainer = SAC_Wrapper(policy=MultiInputPolicy, env=model.env, policy_kwargs=dict(features_extractor_class=CombinedExtractor, net_arch=[512, 512, 512]), learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('/home/hendrik/Documents/master_project/LokalData/ImitationLearning/BC Trainer Large Model/best_modeltensor(-0.2800)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('/home/hendrik/Documents/master_project/LokalData/ImitationLearning/BC MultiInputPolicy 100/best_modeltensor(-0.3200)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_trainer.policy.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_trainer_wrapped = TP_Wrapper(policy='MultiInputPolicy', env=model.env, learning_rate=1e-3, policy_kwargs = dict(net_arch=[512, 512, 512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_trainer_wrapped.policy.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policy(\n",
    "    trainer=continue_trainer,\n",
    "    learn_fct=continue_trainer.learn_fct,\n",
    "    val_env=model.env,\n",
    "    logname='Continue SAC 100',\n",
    "    path='/home/hendrik/Documents/master_project/LokalData/ImitationLearning/',\n",
    "    n_epochs=1000,\n",
    "    n_steps=50,\n",
    "    eval_epochs=100,\n",
    "    step_fct=lambda i: i+1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global NUM_RESETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load('/home/hendrik/Documents/master_project/LokalData/ImitationLearning/BC Trainer Large Model/last_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_trainer.policy.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_policy(policy=continue_trainer.policy, path='/home/hendrik/Documents/master_project/LokalData/ImitationLearning/load_plicy/', logname='best val policy SAC', eval_epochs=500, val_env=model.env, stepid=1, best_reward=-100, save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(continue_trainer.policy.state_dict(), '/home/hendrik/Documents/master_project/LokalData/ImitationLearning/BC Trainer Large Model/last_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bee90e249730b85f00f3915f0cf4f21bc0729131dcc7008c941068256fd0d344"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tfTest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
