{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from imitation.algorithms import bc\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from utilsMW.dataLoaderMW import TorchDatasetMWToy\n",
    "import warnings\n",
    "from typing import Any, Dict, Optional, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from gym import spaces\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from stable_baselines3.common.on_policy_algorithm import OnPolicyAlgorithm\n",
    "from stable_baselines3.common.policies import ActorCriticCnnPolicy, ActorCriticPolicy, BasePolicy, MultiInputActorCriticPolicy\n",
    "from stable_baselines3.common.type_aliases import GymEnv, MaybeCallback, Schedule\n",
    "from stable_baselines3.common.utils import explained_variance,  get_schedule_fn\n",
    "\n",
    "from searchTest.toyEnvironment import check_outpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '/home/hendrik/Documents/master_project/LokalData/metaworld/small/train/'\n",
    "path_validate = '/home/hendrik/Documents/master_project/LokalData/metaworld/small/val/'\n",
    "train_data = TorchDatasetMWToy(path=path_train, device='cpu')\n",
    "val_data = TorchDatasetMWToy(path=path_validate, device='cpu')\n",
    "print(train_data.data.shape)\n",
    "print(train_data.label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "env.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_env():\n",
    "    def __init__(self, train_data):\n",
    "        #obs = step, data, action, current_env\n",
    "        self.observation_space = gym.spaces.box.Box(np.array([0, -2,-2,-2,-2, 0,0,0,0.,0]), np.array([6, 2,2,2,2, 1,1,1,1.,train_data.data.size(0)]), (10,), float)\n",
    "        #next state (4)\n",
    "        self.action_space = gym.spaces.box.Box(np.array([0,0,0,0]), np.array([1,1,1,1]), (4,), float)\n",
    "        self.metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}\n",
    "        self.steps = 0\n",
    "        self.current_env = -1\n",
    "        self.data = train_data.data\n",
    "        self.label = train_data.label\n",
    "        self.traj = None\n",
    "    def reset(self):\n",
    "        self.traj = None\n",
    "        self.current_env = (self.current_env + 1)%len(self.data)\n",
    "        self.steps = 0\n",
    "        last_action = torch.zeros(4, dtype=float, device=self.data.device)\n",
    "        step = torch.tensor(self.steps, device=self.data.device)\n",
    "        current_env = torch.tensor(self.current_env, device=self.data.device)\n",
    "        data = self.data[self.current_env, 0]\n",
    "        #label = self.label[self.current_env,0]\n",
    "        state = torch.cat((step.view(1), data, last_action, current_env.view(1)), dim=0)\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        if type(action) is np.ndarray:\n",
    "            action = torch.tensor(action, device=self.data.device)\n",
    "        if self.traj is None:\n",
    "            self.traj = action.reshape(1,-1)\n",
    "        else:\n",
    "            self.traj = torch.cat((self.traj, action.reshape(1,-1)), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "        self.steps += 1\n",
    "        step = torch.tensor(self.steps, device=self.data.device)\n",
    "        current_env = torch.tensor(self.current_env, device=self.data.device)\n",
    "\n",
    "        #label = self.label[self.current_env, self.current_step]\n",
    "        data = self.data[self.current_env, 0]\n",
    "\n",
    "        state = torch.cat((step.view(1), data, action.reshape(-1), current_env.view(1)))\n",
    "        if self.steps >= self.label.size(1):\n",
    "            tol_neg = -0.55*torch.ones([self.traj.size(-1)])\n",
    "            tol_pos = 0.7*torch.ones([self.traj.size(-1)])\n",
    "            reward = int(check_outpt(self.label[self.current_env].unsqueeze(0), self.traj.unsqueeze(0), tol_neg=tol_neg, tol_pos=tol_pos))\n",
    "            return (state, reward, True, {})\n",
    "        else:\n",
    "            return (state, 0., False, {})\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self, mode):\n",
    "        pass\n",
    "\n",
    "class toy_exper_model(OnPolicyAlgorithm):\n",
    "    def __init__(\n",
    "            self,\n",
    "            policy: Union[str, Type[ActorCriticPolicy]] = 'MlpPolicy',\n",
    "            env: Union[GymEnv, str] = None,\n",
    "            learning_rate: Union[float, Schedule] = 3e-4,\n",
    "            n_steps: int = 2048,\n",
    "            batch_size: int = 64,\n",
    "            n_epochs: int = 10,\n",
    "            gamma: float = 0.99,\n",
    "            gae_lambda: float = 0.95,\n",
    "            clip_range: Union[float, Schedule] = 0.2,\n",
    "            clip_range_vf: Union[None, float, Schedule] = None,\n",
    "            normalize_advantage: bool = True,\n",
    "            ent_coef: float = 0.0,\n",
    "            vf_coef: float = 0.5,\n",
    "            max_grad_norm: float = 0.5,\n",
    "            use_sde: bool = False,\n",
    "            sde_sample_freq: int = -1,\n",
    "            target_kl: Optional[float] = None,\n",
    "            tensorboard_log: Optional[str] = None,\n",
    "            create_eval_env: bool = False,\n",
    "            policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "            verbose: int = 0,\n",
    "            seed: Optional[int] = None,\n",
    "            device: Union[th.device, str] = \"auto\",\n",
    "            _init_setup_model: bool = True,\n",
    "            train_data = None\n",
    "        ):\n",
    "        super().__init__(\n",
    "            policy,\n",
    "            env,\n",
    "            learning_rate=learning_rate,\n",
    "            n_steps=n_steps,\n",
    "            gamma=gamma,\n",
    "            gae_lambda=gae_lambda,\n",
    "            ent_coef=ent_coef,\n",
    "            vf_coef=vf_coef,\n",
    "            max_grad_norm=max_grad_norm,\n",
    "            use_sde=use_sde,\n",
    "            sde_sample_freq=sde_sample_freq,\n",
    "            tensorboard_log=tensorboard_log,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            verbose=verbose,\n",
    "            device=device,\n",
    "            create_eval_env=create_eval_env,\n",
    "            seed=seed,\n",
    "            _init_setup_model=False,\n",
    "            supported_action_spaces=(\n",
    "                spaces.Box,\n",
    "                spaces.Discrete,\n",
    "                spaces.MultiDiscrete,\n",
    "                spaces.MultiBinary,\n",
    "            ),\n",
    "        )\n",
    "        self.data = train_data.data\n",
    "        self.label = train_data.label\n",
    "\n",
    "\n",
    "    def predict(self, obs, state=None, episode_start=None, deterministic=False):\n",
    "        step = int(obs.reshape(-1)[0])\n",
    "        env = int(obs.reshape(-1)[-1])\n",
    "        return self.label[env, step].reshape(1, -1), self.label[env, step].reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = my_env(train_data=train_data)\n",
    "val_env = my_env(train_data=val_data)\n",
    "my_expert = toy_exper_model(train_data=train_data, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_expert_transitions():\n",
    "    expert = my_expert\n",
    "\n",
    "    print(\"Sampling expert transitions.\")\n",
    "    rollouts = rollout.rollout(\n",
    "        expert,\n",
    "        DummyVecEnv([lambda: RolloutInfoWrapper(env)]),\n",
    "        rollout.make_sample_until(min_timesteps=None, min_episodes=10000),\n",
    "    )\n",
    "    return rollout.flatten_trajectories(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @author Simon Stepputtis <sstepput@asu.edu>, Interactive Robotics Lab, Arizona State University\n",
    "\n",
    "from pickle import NONE\n",
    "from urllib.parse import non_hierarchical\n",
    "#matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from hashids import Hashids\n",
    "import cv2\n",
    "import os\n",
    "from MetaWorld.searchTest.toyEnvironment import make_sliding_tol\n",
    "\n",
    "\n",
    "\n",
    "class TBoardGraphsTorch():\n",
    "    def __init__(self, logname= None, data_path = None):\n",
    "        if logname is not None:\n",
    "            self.__hashids           = Hashids()\n",
    "            #self.logdir              = \"Data/TBoardLog/\" + logname + \"/\"\n",
    "            self.logdir              = os.path.join(data_path, \"gboard/\" + logname + \"/\")\n",
    "            print(f'log dir: {self.logdir + \"train/\"}')\n",
    "            self.__tboard_train      = tf.summary.create_file_writer(self.logdir + \"train/\")\n",
    "            self.__tboard_validation = tf.summary.create_file_writer(self.logdir + \"validate/\")\n",
    "            #self.voice               = Voice(path=data_path)\n",
    "        self.fig, self.ax = plt.subplots(3,3)\n",
    "\n",
    "    def startDebugger(self):\n",
    "        tf.summary.trace_on(graph=True, profiler=True)\n",
    "    \n",
    "    def stopDebugger(self):\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=self.logdir)\n",
    "\n",
    "    def finishFigure(self, fig):\n",
    "        fig.canvas.draw()\n",
    "        data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "        data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        return data\n",
    "    \n",
    "    def addTrainScalar(self, name, value, stepid):\n",
    "        with self.__tboard_train.as_default():\n",
    "            tfvalue = self.torch2tf(value)\n",
    "            tf.summary.scalar(name, tfvalue, step=stepid)\n",
    "\n",
    "    def addValidationScalar(self, name, value, stepid):\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tfvalue = self.torch2tf(value)\n",
    "            tf.summary.scalar(name, tfvalue, step=stepid)\n",
    "\n",
    "    def torch2tf(self, inpt):\n",
    "        if inpt is not None:\n",
    "            return tf.convert_to_tensor(inpt.detach().cpu().numpy())\n",
    "        else:\n",
    "            return inpt\n",
    "\n",
    "    def plotTrajectory(self, y_true, y_pred, dt_true, dt_pred, stepid):\n",
    "        tf_y_true = self.torch2tf(y_true)\n",
    "        tf_y_pred = self.torch2tf(y_pred)\n",
    "        tf_dt_true = self.torch2tf(dt_true)\n",
    "        tf_dt_pred = self.torch2tf(dt_pred)\n",
    "\n",
    "        fig, ax = plt.subplots(3,3)\n",
    "        fig.set_size_inches(9, 9)\n",
    "\n",
    "        tf_dt_true = 1.0/tf_dt_true.numpy()\n",
    "        tf_dt_pred = 1.0/tf_dt_pred.numpy()[0]\n",
    "\n",
    "        max_trj_len = tf_y_true.shape[0]\n",
    "        for sp in range(7):\n",
    "            idx = sp // 3\n",
    "            idy = sp  % 3\n",
    "            ax[idx,idy].clear()\n",
    "            ax[idx,idy].plot(range(max_trj_len), tf_y_pred[:,sp], alpha=0.5, color='midnightblue')\n",
    "            ax[idx,idy].plot(range(max_trj_len), tf_y_true[:,sp], alpha=0.5, color='forestgreen')\n",
    "            # ax[idx,idy].plot([dt_pred, dt_pred], [-0.1, 1.1], alpha=0.5, linestyle=\":\", color=\"midnightblue\")\n",
    "            # ax[idx,idy].plot([dt_true, dt_true], [-0.1, 1.1], alpha=0.5, linestyle=\":\", color=\"forestgreen\")\n",
    "            # ax[idx,idy].set_ylim([-0.1, 1.1])\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Trajectory\", data=result, step=stepid)\n",
    "\n",
    "    def idToText(self, id):\n",
    "        names = [\"\", \"ysr\", \"rsr\", \"gsr\", \"bsr\", \"psr\", \"ylr\", \"rlr\", \"glr\", \"blr\", \"plr\", \"yss\", \"rss\", \"gss\", \"bss\", \"pss\", \"yls\", \"rls\", \"gls\", \"bls\", \"pls\"]\n",
    "        return names[id]\n",
    "\n",
    "    def plotImageRegions(self, image, image_dict, stepid):\n",
    "        # Visualization of the results of a detection.\n",
    "        num_detected = len([v for v in image_dict[\"detection_scores\"][0] if v > 0.5]) \n",
    "        image_np     = image.numpy()       \n",
    "        for i in range(num_detected):\n",
    "            ymin, xmin, ymax, xmax = image_dict['detection_boxes'][0][i,:]\n",
    "            pt1 = (int(xmin*image_np.shape[1]), int(ymin*image_np.shape[0]))\n",
    "            pt2 = (int(xmax*image_np.shape[1]), int(ymax*image_np.shape[0]))\n",
    "            image_np = cv2.rectangle(image_np, pt1, pt2, (255, 0, 0), 2)\n",
    "            image_np = cv2.putText(image_np, self.idToText(image_dict['detection_classes'][0][i]) + \" {:.1f}%\".format(image_dict[\"detection_scores\"][0][i] * 100), pt1, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(image_np)\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Image\", data=result, step=stepid)\n",
    "\n",
    "    def plotAttention(self, attention_weights, image_dict, language, stepid):\n",
    "        tf_attention_weights = self.torch2tf(attention_weights)\n",
    "        tf_language = self.torch2tf(language)\n",
    "\n",
    "        tf_attention_weights = tf_attention_weights.numpy()\n",
    "        classes           = image_dict[\"detection_classes\"][0][:len(tf_attention_weights)].numpy().astype(dtype=np.int32)\n",
    "        classes           = [self.idToText(i) for i in classes]\n",
    "        x                 = np.arange(len(tf_attention_weights))\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        plt.bar(x, tf_attention_weights)\n",
    "        plt.xticks(x, classes)\n",
    "        ax.set_ylim([0, 1])\n",
    "        plt.text(0.01, 0.95, self.voice.tokensToSentence(tf_language.numpy().tolist()), horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Attention\", data=result, step=stepid)\n",
    "    \n",
    "    def plotClassAccuracy(self, gt_class, pred_class, pred_class_std, language, stepid):\n",
    "        labels     = [\"ysr\", \"rsr\", \"gsr\", \"bsr\", \"psr\", \"ylr\", \"rlr\", \"glr\", \"blr\", \"plr\", \"yss\", \"rss\", \"gss\", \"bss\", \"pss\", \"yls\", \"rls\", \"gls\", \"bls\", \"pls\"]\n",
    "        tf_gt_class = self.torch2tf(gt_class)\n",
    "        tf_pred_class = self.torch2tf(pred_class)\n",
    "        tf_language = self.torch2tf(language)\n",
    "\n",
    "        \n",
    "        \n",
    "        tf_gt_class   = tf_gt_class.numpy()\n",
    "        tf_pred_class = tf_pred_class.numpy()\n",
    "        x          = np.arange(len(tf_gt_class))\n",
    "        width      = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        #rects1 = ax.bar(x - width/2, gt_class, width, label='GT', color=\"forestgreen\")\n",
    "        #rects2 = ax.bar(x + width/2, pred_class, width, yerr=pred_class_std, label='Pred', color=\"midnightblue\")\n",
    "        ax.set_xticks(x)\n",
    "        # ax.set_xticklabels(labels)\n",
    "        plt.text(0.01, 0.95, self.voice.tokensToSentence(tf_language.numpy().tolist()), horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Attention\", data=result, step=stepid)\n",
    "\n",
    "    def plotDeltaT(self, y_true, y_pred, stepid):\n",
    "        tf_y_true = self.torch2tf(y_true)\n",
    "        tf_y_pred = self.torch2tf(y_pred)\n",
    "\n",
    "        gt = tf_y_true.numpy()\n",
    "        pd = tf_y_pred.numpy()[:,0]\n",
    "        jdata = np.stack((gt,pd), axis=1)\n",
    "        svals = jdata[np.argsort(jdata[:,0]),:]\n",
    "        x     = np.arange(svals.shape[0])\n",
    "        width = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        rects1 = ax.bar(x - width/2, svals[:,0], width, label='GT', color=\"forestgreen\")\n",
    "        rects2 = ax.bar(x + width/2, svals[:,1], width, label='Pred', color=\"midnightblue\")\n",
    "        ax.set_xticks(x)\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"DeltaT\", data=result, step=stepid)\n",
    "\n",
    "    def plotWeights(self, gt_w, pred_w, stepid):\n",
    "        tf_gt_w = self.torch2tf(gt_w)\n",
    "        tf_pred_w = self.torch2tf(pred_w)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2,sharey=True,sharex=True)\n",
    "        # fig.set_size_inches(4, 10)\n",
    "\n",
    "        combined_weights = np.concatenate((tf_gt_w.numpy(), tf_pred_w.numpy()), axis=0).T\n",
    "\n",
    "        ax1.imshow(combined_weights[:,:7], cmap=\"RdBu\")\n",
    "        ax2.imshow(combined_weights[:,7:], cmap=\"RdBu\")\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Weights\", data=result, step=stepid)\n",
    "\n",
    "    def interpolateTrajectory(self, trj, target):\n",
    "        tf_trj = self.torch2tf(trj)\n",
    "        tf_target = self.torch2tf(target)\n",
    "\n",
    "        current_length = tf_trj.shape[0]\n",
    "        dimensions     = tf_trj.shape[1]\n",
    "        result         = np.zeros((tf_target, dimensions), dtype=np.float32)\n",
    "    \n",
    "        for i in range(dimensions):\n",
    "            result[:,i] = np.interp(np.linspace(0.0, 1.0, num=tf_target), np.linspace(0.0, 1.0, num=current_length), trj[:,i])\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def plotDMPTrajectory(self, y_true, y_pred, y_pred_std = None, phase= None, \\\n",
    "        dt= None, p_dt= None, stepid= None, name = \"Trajectory\", save = False, \\\n",
    "            name_plot = None, path=None, tol_neg = None, tol_pos=None, inpt = None, opt_gen_trj=None, window = 0):\n",
    "        tf_y_true = self.torch2tf(y_true)\n",
    "        tf_y_pred = self.torch2tf(y_pred)\n",
    "        tf_phase = self.torch2tf(phase)\n",
    "        tf_inpt = self.torch2tf(inpt)\n",
    "        if p_dt is not None:\n",
    "            tf_dt = self.torch2tf(dt)\n",
    "            tf_p_dt = self.torch2tf(p_dt)\n",
    "        if opt_gen_trj is not None:\n",
    "            tf_opt_gen_trj = self.torch2tf(opt_gen_trj)\n",
    "            tf_opt_gen_trj = tf_opt_gen_trj.numpy()\n",
    "\n",
    "        tf_y_true      = tf_y_true.numpy()\n",
    "        tf_y_pred      = tf_y_pred.numpy()\n",
    "        tf_inpt        = tf_inpt.numpy()\n",
    "        if tf_phase is not None:\n",
    "            tf_phase       = tf_phase.numpy()\n",
    "\n",
    "        if p_dt is not None:\n",
    "            tf_dt          = tf_dt.numpy() * 350.0\n",
    "            tf_p_dt        = tf_p_dt.numpy()\n",
    "        trj_len      = tf_y_true.shape[0]\n",
    "        \n",
    "        #fig, ax = plt.subplots(3,3)\n",
    "        fig, ax = self.fig, self.ax\n",
    "        #fig.set_size_inches(9, 9)\n",
    "        if window > 0:\n",
    "            neg_inpt, pos_inpt, tf_y_true = make_sliding_tol(label=y_true.unsqueeze(0), neg_tol=tol_neg, pos_tol=tol_pos, window=window)\n",
    "            tf_y_true = tf_y_true[0].detach().cpu().numpy()\n",
    "            trj_len      = tf_y_true.shape[0]\n",
    "            tf_y_pred = y_pred[int(window/2):-(int(window/2) + 1)].detach().cpu().numpy()\n",
    "            neg_inpt = neg_inpt.detach().cpu().numpy()\n",
    "            pos_inpt = pos_inpt.detach().cpu().numpy()\n",
    "            if opt_gen_trj is not None:\n",
    "                tf_opt_gen_trj = opt_gen_trj[int(window/2):-(int(window/2) + 1)].detach().cpu().numpy()\n",
    "        else:\n",
    "            neg_inpt = tf_y_true + tol_neg[None,:].cpu().numpy()\n",
    "            pos_inpt = tf_y_true + tol_pos[None,:].cpu().numpy()\n",
    "        for sp in range(len(tf_y_true[0])):\n",
    "            idx = sp // 3\n",
    "            idy = sp  % 3\n",
    "            ax[idx,idy].clear()\n",
    "\n",
    "            # GT Trajectory:\n",
    "            if tol_neg is not None:\n",
    "\n",
    "                ax[idx,idy].plot(range(tf_y_pred.shape[0]), neg_inpt[:,sp], alpha=0.75, color='orangered')\n",
    "                ax[idx,idy].plot(range(tf_y_pred.shape[0]), pos_inpt[:,sp], alpha=0.75, color='orangered')\n",
    "            ax[idx,idy].plot(range(trj_len), tf_y_true[:,sp],   alpha=1.0, color='forestgreen')            \n",
    "            ax[idx,idy].plot(range(tf_y_pred.shape[0]), tf_y_pred[:,sp], alpha=0.75, color='mediumslateblue')\n",
    "            if opt_gen_trj is not None:\n",
    "                ax[idx,idy].plot(range(tf_y_pred.shape[0]), tf_opt_gen_trj[:,sp], alpha=0.75, color='lightseagreen')\n",
    "                diff_vec = tf_opt_gen_trj - tf_y_pred\n",
    "                ax[idx,idy].plot(range(tf_y_pred.shape[0]), diff_vec[:,sp], alpha=0.75, color='pink')\n",
    "\n",
    "            #ax[idx,idy].errorbar(range(tf_y_pred.shape[0]), tf_y_pred[:,sp], xerr=None, yerr=None, alpha=0.25, fmt='none', color='mediumslateblue')\n",
    "            #ax[idx,idy].set_ylim([-0.1, 1.1])\n",
    "            if p_dt is not None:\n",
    "                ax[idx,idy].plot([tf_dt, tf_dt], [0.0,1.0], linestyle=\":\", color='forestgreen')\n",
    "\n",
    "        if inpt is not None:\n",
    "            ax[-1,-1].clear()\n",
    "            ax[-1,-1].plot(range(inpt.shape[-1]), tf_inpt,   alpha=1.0, color='forestgreen')     \n",
    "        \n",
    "        if tf_phase is not None:\n",
    "            ax[2,2].clear()\n",
    "            ax[2,2].plot(range(tf_y_pred.shape[0]), tf_phase, color='orange')\n",
    "        if p_dt is not None:\n",
    "            ax[2,2].plot([tf_dt, tf_dt], [0.0,1.0], linestyle=\":\", color='forestgreen')\n",
    "            ax[2,2].plot([tf_p_dt*350.0, tf_p_dt*350.0], [0.0,1.0], linestyle=\":\", color='mediumslateblue')\n",
    "            ax[2,2].set_ylim([-0.1, 1.1])\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        if save:\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            plt.savefig(path + name_plot + '.png')\n",
    "        #fig.clear()\n",
    "        #plt.close()\n",
    "        if not save:\n",
    "            with self.__tboard_validation.as_default():\n",
    "                tf.summary.image(name, data=result, step=stepid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBoardGraphsTorch():\n",
    "    def __init__(self, logname= None, data_path = None):\n",
    "        if logname is not None:\n",
    "            self.__hashids           = Hashids()\n",
    "            #self.logdir              = \"Data/TBoardLog/\" + logname + \"/\"\n",
    "            self.logdir              = os.path.join(data_path, \"gboard/\" + logname + \"/\")\n",
    "            print(f'log dir: {self.logdir + \"train/\"}')\n",
    "            self.__tboard_train      = tf.summary.create_file_writer(self.logdir + \"train/\")\n",
    "            self.__tboard_validation = tf.summary.create_file_writer(self.logdir + \"validate/\")\n",
    "        self.fig, self.ax = plt.subplots(3,3)\n",
    "\n",
    "    def startDebugger(self):\n",
    "        tf.summary.trace_on(graph=True, profiler=True)\n",
    "    \n",
    "    def stopDebugger(self):\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=self.logdir)\n",
    "\n",
    "    def finishFigure(self, fig):\n",
    "        fig.canvas.draw()\n",
    "        data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "        data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        return data\n",
    "    \n",
    "    def addTrainScalar(self, name, value, stepid):\n",
    "        with self.__tboard_train.as_default():\n",
    "            tfvalue = self.torch2tf(value)\n",
    "            tf.summary.scalar(name, tfvalue, step=stepid)\n",
    "\n",
    "    def addValidationScalar(self, name, value, stepid):\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tfvalue = self.torch2tf(value)\n",
    "            tf.summary.scalar(name, tfvalue, step=stepid)\n",
    "\n",
    "    def torch2tf(self, inpt):\n",
    "        if inpt is not None:\n",
    "            return tf.convert_to_tensor(inpt.detach().cpu().numpy())\n",
    "        else:\n",
    "            return inpt\n",
    "def Voice(path):\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashids import Hashids\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tboard = TBoardGraphsTorch(logname='asd', data_path='/home/hendrik/Documents/master_project/LokalData/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.policies import *\n",
    "\n",
    "policy = ActorCriticPolicy(observation_space=env.observation_space, action_space=env.action_space, lr_schedule=lambda _: torch.finfo(torch.float32).max, net_arch = [dict(pi=[200, 200], vf=[200, 200])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = sample_expert_transitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    demonstrations=transitions,\n",
    "    policy=policy,\n",
    "    device='cpu'\n",
    ")\n",
    "#bc_trainer.train(n_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log dir: /home/hendrik/Documents/master_project/LokalData/test/gboard/asd/train/\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TBoardGraphsTorch' object has no attribute 'plotDMPTrajectory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/hendrik/Documents/master_project/Code/MetaWorld/stable_baseline.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/MetaWorld/stable_baseline.ipynb#ch0000018?line=12'>13</a>\u001b[0m     tol_neg \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.55\u001b[39m\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mones([val_env\u001b[39m.\u001b[39mtraj\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/MetaWorld/stable_baseline.ipynb#ch0000018?line=13'>14</a>\u001b[0m     tol_pos \u001b[39m=\u001b[39m \u001b[39m0.7\u001b[39m\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mones([val_env\u001b[39m.\u001b[39mtraj\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/MetaWorld/stable_baseline.ipynb#ch0000018?line=14'>15</a>\u001b[0m     tboard\u001b[39m.\u001b[39;49mplotDMPTrajectory(target_trj, gen_trj, torch\u001b[39m.\u001b[39mzeros_like(gen_trj),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/MetaWorld/stable_baseline.ipynb#ch0000018?line=15'>16</a>\u001b[0m                                 \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, stepid\u001b[39m=\u001b[39mi, save\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name_plot\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimitation baseline\u001b[39m\u001b[39m'\u001b[39m, path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/MetaWorld/stable_baseline.ipynb#ch0000018?line=16'>17</a>\u001b[0m                                     tol_neg\u001b[39m=\u001b[39mtol_neg, tol_pos\u001b[39m=\u001b[39mtol_pos, inpt \u001b[39m=\u001b[39m inpt, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimitation baseline\u001b[39m\u001b[39m'\u001b[39m, opt_gen_trj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, window\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/MetaWorld/stable_baseline.ipynb#ch0000018?line=17'>18</a>\u001b[0m     rew\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/MetaWorld/stable_baseline.ipynb#ch0000018?line=18'>19</a>\u001b[0m reward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(rew)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39mmean()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TBoardGraphsTorch' object has no attribute 'plotDMPTrajectory'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tboard = TBoardGraphsTorch(logname='asd', data_path='/home/hendrik/Documents/master_project/LokalData/test/')\n",
    "for i in range(100):\n",
    "    rew = []\n",
    "    for j in range(1000):\n",
    "        obs = val_env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = bc_trainer.policy.predict(obs)\n",
    "            obs, reward, done, _ = val_env.step(action=action)\n",
    "        target_trj = val_env.label[val_env.current_env].unsqueeze(0)\n",
    "        gen_trj = val_env.traj.unsqueeze(0)\n",
    "        inpt = val_env.data[val_env.current_env].unsqueeze(0)\n",
    "        tol_neg = -0.55*torch.ones([val_env.traj.size(-1)])\n",
    "        tol_pos = 0.7*torch.ones([val_env.traj.size(-1)])\n",
    "        tboard.plotDMPTrajectory(target_trj, gen_trj, torch.zeros_like(gen_trj),\n",
    "                                    None, None, None, stepid=i, save=False, name_plot='imitation baseline', path='',\\\n",
    "                                        tol_neg=tol_neg, tol_pos=tol_pos, inpt = inpt, name='imitation baseline', opt_gen_trj = None, window=None)\n",
    "        rew.append(reward)\n",
    "    reward = torch.tensor(rew).type(torch.float).mean()\n",
    "    print(reward)\n",
    "    tboard.addValidationScalar('success rate', reward.detach(), stepid=i)\n",
    "    #bc_trainer.train(n_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, _ = evaluate_policy(bc_trainer.policy, env, n_eval_episodes=3, render=True)\n",
    "print(f\"Reward before training: {reward}\")\n",
    "\n",
    "print(\"Training a policy using Behavior Cloning\")\n",
    "bc_trainer.train(n_epochs=10)\n",
    "\n",
    "reward, _ = evaluate_policy(bc_trainer.policy, env, n_eval_episodes=3, render=True)\n",
    "print(f\"Reward after training: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, _ = evaluate_policy(bc_trainer.policy, env, n_eval_episodes=3, render=True)\n",
    "print(f\"Reward before training: {reward}\")\n",
    "\n",
    "print(\"Training a policy using Behavior Cloning\")\n",
    "bc_trainer.train(n_epochs=1)\n",
    "\n",
    "reward, _ = evaluate_policy(bc_trainer.policy, env, n_eval_episodes=3, render=True)\n",
    "print(f\"Reward after training: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, _ = evaluate_policy(bc_trainer.policy, env, n_eval_episodes=3, render=True)\n",
    "print(f\"Reward before training: {reward}\")\n",
    "\n",
    "print(\"Training a policy using Behavior Cloning\")\n",
    "bc_trainer.train(n_epochs=1)\n",
    "\n",
    "reward, _ = evaluate_policy(bc_trainer.policy, env, n_eval_episodes=3, render=True)\n",
    "print(f\"Reward after training: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = gym.make(\"CartPole-v1\")\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(action)\n",
    "    print(obs)\n",
    "    #env.render()\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6edd83f9b3fcb9454c0e509bb1e55f01736f244b1bbba81ee1367549d9ea0fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mujoco')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
