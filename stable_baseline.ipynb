{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from imitation.algorithms import bc\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from utilsMW.dataLoaderMW import TorchDatasetMWToy\n",
    "from typing import Any, Dict, Optional, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3.common.on_policy_algorithm import OnPolicyAlgorithm\n",
    "from stable_baselines3.common.policies import ActorCriticCnnPolicy, ActorCriticPolicy, BasePolicy\n",
    "from stable_baselines3.common.type_aliases import GymEnv, MaybeCallback\n",
    "\n",
    "from searchTest.toyEnvironment import check_outpt\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class asdasd(torch.utils.data.Dataset):\n",
    "    def __init__(self, asd):\n",
    "        print('init')\n",
    "        self.data = torch.arange(10)\n",
    "        print(len(self.data))\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        print(len(self.data))\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/hendrik/Documents/master_project/LokalData/metaworld/pick-place/training_data/'\n",
    "device = 'cuda'\n",
    "batch_size = 2\n",
    "#train_data = TorchDatasetMW(path=path, device=device)\n",
    "train_data = asdasd(asd=1)\n",
    "train_indices = torch.randperm(int(len(train_data)))\n",
    "train_indices = train_indices[:int(len(train_indices)*1)]\n",
    "print(len(train_data))\n",
    "train_data = torch.utils.data.Subset(train_data, [0])\n",
    "print(f'len(train_data): {len(train_data)}')\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '/home/hendrik/Documents/master_project/LokalData/metaworld/small/train/'\n",
    "path_validate = '/home/hendrik/Documents/master_project/LokalData/metaworld/small/val/'\n",
    "train_data = TorchDatasetMWToy(path=path_train, device='cpu')\n",
    "val_data = TorchDatasetMWToy(path=path_validate, device='cpu')\n",
    "print(train_data.data.shape)\n",
    "print(train_data.label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global SAMPLED_ENVS\n",
    "global STEPS_TAKEN\n",
    "SAMPLED_ENVS = 0\n",
    "STEPS_TAKEN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_env():\n",
    "    def __init__(self, train_data):\n",
    "        #obs = step, data, action, current_env\n",
    "        self.observation_space = gym.spaces.box.Box(np.array([0, -2,-2,-2,-2, 0,0,0,0.,0]), np.array([6, 2,2,2,2, 1,1,1,1.,train_data.data.size(0)]), (10,), float)\n",
    "        #next state (4)\n",
    "        self.action_space = gym.spaces.box.Box(np.array([0,0,0,0]), np.array([1,1,1,1]), (4,), float)\n",
    "        self.metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}\n",
    "        self.steps = 0\n",
    "        self.current_env = -1\n",
    "        self.data = train_data.data\n",
    "        self.label = train_data.label\n",
    "        self.traj = None\n",
    "        self.num_envs = 1\n",
    "    def reset(self):\n",
    "        global SAMPLED_ENVS\n",
    "        global STEPS_TAKEN\n",
    "        STEPS_TAKEN += 1\n",
    "        SAMPLED_ENVS += 1\n",
    "        self.traj = None\n",
    "        self.current_env = (self.current_env + 1)%len(self.data)\n",
    "        self.steps = 0\n",
    "        last_action = torch.zeros(4, dtype=float, device=self.data.device)\n",
    "        step = torch.tensor(self.steps, device=self.data.device)\n",
    "        current_env = torch.tensor(self.current_env, device=self.data.device)\n",
    "        data = self.data[self.current_env, 0]\n",
    "        #label = self.label[self.current_env,0]\n",
    "        state = torch.cat((step.view(1), data, last_action, current_env.view(1)), dim=0).numpy()\n",
    "        #print(f'reset: {state.shape}')\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        global STEPS_TAKEN\n",
    "        STEPS_TAKEN += 1\n",
    "        if type(action) is np.ndarray:\n",
    "            action = torch.tensor(action, device=self.data.device)\n",
    "        if self.traj is None:\n",
    "            self.traj = action.reshape(1,-1)\n",
    "        else:\n",
    "            self.traj = torch.cat((self.traj, action.reshape(1,-1)), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "        self.steps += 1\n",
    "        step = torch.tensor(self.steps, device=self.data.device)\n",
    "        current_env = torch.tensor(self.current_env, device=self.data.device)\n",
    "\n",
    "        #label = self.label[self.current_env, self.current_step]\n",
    "        data = self.data[self.current_env, 0]\n",
    "\n",
    "        state = torch.cat((step.view(1), data, action.reshape(-1), current_env.view(1)), dim=0).numpy()\n",
    "        #print(f'step: {state.shape}')\n",
    "\n",
    "        if self.steps >= self.label.size(1):\n",
    "            tol_neg = -0.55*torch.ones([self.traj.size(-1)])\n",
    "            tol_pos = 0.7*torch.ones([self.traj.size(-1)])\n",
    "            reward = int(check_outpt(self.label[self.current_env].unsqueeze(0), self.traj.unsqueeze(0), tol_neg=tol_neg, tol_pos=tol_pos))\n",
    "            return (state, reward, True, {})\n",
    "        else:\n",
    "            return (state, 0., False, {})\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self, mode):\n",
    "        pass\n",
    "\n",
    "class toy_exper_model(OnPolicyAlgorithm):\n",
    "    def __init__(\n",
    "            self,\n",
    "            policy: Union[str, Type[ActorCriticPolicy]] = 'MlpPolicy',\n",
    "            env: Union[GymEnv, str] = None,\n",
    "            learning_rate = 3e-4,\n",
    "            n_steps: int = 2048,\n",
    "            batch_size: int = 64,\n",
    "            n_epochs: int = 10,\n",
    "            gamma: float = 0.99,\n",
    "            gae_lambda: float = 0.95,\n",
    "            clip_range = 0.2,\n",
    "            clip_range_vf = None,\n",
    "            normalize_advantage: bool = True,\n",
    "            ent_coef: float = 0.0,\n",
    "            vf_coef: float = 0.5,\n",
    "            max_grad_norm: float = 0.5,\n",
    "            use_sde: bool = False,\n",
    "            sde_sample_freq: int = -1,\n",
    "            target_kl: Optional[float] = None,\n",
    "            tensorboard_log: Optional[str] = None,\n",
    "            create_eval_env: bool = False,\n",
    "            policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "            verbose: int = 0,\n",
    "            seed: Optional[int] = None,\n",
    "            device: Union[th.device, str] = \"auto\",\n",
    "            _init_setup_model: bool = True,\n",
    "            train_data = None\n",
    "        ):\n",
    "        super().__init__(\n",
    "            policy,\n",
    "            env,\n",
    "            learning_rate=learning_rate,\n",
    "            n_steps=n_steps,\n",
    "            gamma=gamma,\n",
    "            gae_lambda=gae_lambda,\n",
    "            ent_coef=ent_coef,\n",
    "            vf_coef=vf_coef,\n",
    "            max_grad_norm=max_grad_norm,\n",
    "            use_sde=use_sde,\n",
    "            sde_sample_freq=sde_sample_freq,\n",
    "            tensorboard_log=tensorboard_log,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            verbose=verbose,\n",
    "            device=device,\n",
    "            create_eval_env=create_eval_env,\n",
    "            seed=seed,\n",
    "            _init_setup_model=False,\n",
    "        )\n",
    "        self.data = train_data.data\n",
    "        self.label = train_data.label\n",
    "        #obs = step, data, action, current_env\n",
    "        self.observation_space = gym.spaces.box.Box(np.array([0, -2,-2,-2,-2, 0,0,0,0,0]), np.array([6, 2,2,2,2, 1,1,1,1,train_data.data.size(0)]), (10,), float)\n",
    "        #next state (4)\n",
    "        self.action_space = gym.spaces.box.Box(np.array([0,0,0,0]), np.array([1,1,1,1]), (4,), float)\n",
    "\n",
    "    def predict(self, obs, state=None, episode_start=None, deterministic=False):\n",
    "        step = int(obs.reshape(-1)[0])\n",
    "        env = int(obs.reshape(-1)[-1])\n",
    "        #print(f'expert: {self.label[env, step].reshape(1, -1).shape}')\n",
    "        return self.label[env, step].reshape(1, -1), self.label[env, step].reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_env = my_env(train_data=train_data)\n",
    "val_env = my_env(train_data=val_data)\n",
    "my_expert = toy_exper_model(train_data=train_data, env=toy_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLED_ENVS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_expert_transitions():\n",
    "    expert = my_expert\n",
    "\n",
    "    print(\"Sampling expert transitions.\")\n",
    "    rollouts = rollout.generate_trajectories(\n",
    "        expert,\n",
    "        DummyVecEnv([lambda: RolloutInfoWrapper(toy_env)]),\n",
    "        rollout.make_sample_until(n_episodes=1000, n_timesteps=None),\n",
    "    )\n",
    "    return rollout.flatten_trajectories(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = sample_expert_transitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLED_ENVS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @author Simon Stepputtis <sstepput@asu.edu>, Interactive Robotics Lab, Arizona State University\n",
    "\n",
    "from pickle import NONE\n",
    "from urllib.parse import non_hierarchical\n",
    "#matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from hashids import Hashids\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class TBoardGraphsTorch():\n",
    "    def __init__(self, logname= None, data_path = None, prefix = ''):\n",
    "        if logname is not None:\n",
    "            self.__hashids           = Hashids()\n",
    "            #self.logdir              = \"Data/TBoardLog/\" + logname + \"/\"\n",
    "            self.logdir              = os.path.join(data_path, \"gboard/\" + logname + \"/\")\n",
    "            print(f'log dir: {self.logdir + \"train/\"}')\n",
    "            self.__tboard_train      = tf.summary.create_file_writer(self.logdir + prefix + \"train/\")\n",
    "            self.__tboard_validation = tf.summary.create_file_writer(self.logdir + prefix + \"validate/\")\n",
    "            #self.voice               = Voice(path=data_path)\n",
    "        self.fig, self.ax = plt.subplots(3,3)\n",
    "\n",
    "    def startDebugger(self):\n",
    "        tf.summary.trace_on(graph=True, profiler=True)\n",
    "    \n",
    "    def stopDebugger(self):\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=self.logdir)\n",
    "\n",
    "    def finishFigure(self, fig):\n",
    "        fig.canvas.draw()\n",
    "        data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "        data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        return data\n",
    "    \n",
    "    def addTrainScalar(self, name, value, stepid):\n",
    "        with self.__tboard_train.as_default():\n",
    "            tfvalue = self.torch2tf(value)\n",
    "            tf.summary.scalar(name, tfvalue, step=stepid)\n",
    "\n",
    "    def addValidationScalar(self, name, value, stepid):\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tfvalue = self.torch2tf(value)\n",
    "            tf.summary.scalar(name, tfvalue, step=stepid)\n",
    "\n",
    "    def torch2tf(self, inpt):\n",
    "        if inpt is not None:\n",
    "            return tf.convert_to_tensor(inpt.detach().cpu().numpy())\n",
    "        else:\n",
    "            return inpt\n",
    "\n",
    "    def plotTrajectory(self, y_true, y_pred, dt_true, dt_pred, stepid):\n",
    "        tf_y_true = self.torch2tf(y_true)\n",
    "        tf_y_pred = self.torch2tf(y_pred)\n",
    "        tf_dt_true = self.torch2tf(dt_true)\n",
    "        tf_dt_pred = self.torch2tf(dt_pred)\n",
    "\n",
    "        fig, ax = plt.subplots(3,3)\n",
    "        fig.set_size_inches(9, 9)\n",
    "\n",
    "        tf_dt_true = 1.0/tf_dt_true.numpy()\n",
    "        tf_dt_pred = 1.0/tf_dt_pred.numpy()[0]\n",
    "\n",
    "        max_trj_len = tf_y_true.shape[0]\n",
    "        for sp in range(7):\n",
    "            idx = sp // 3\n",
    "            idy = sp  % 3\n",
    "            ax[idx,idy].clear()\n",
    "            ax[idx,idy].plot(range(max_trj_len), tf_y_pred[:,sp], alpha=0.5, color='midnightblue')\n",
    "            ax[idx,idy].plot(range(max_trj_len), tf_y_true[:,sp], alpha=0.5, color='forestgreen')\n",
    "            # ax[idx,idy].plot([dt_pred, dt_pred], [-0.1, 1.1], alpha=0.5, linestyle=\":\", color=\"midnightblue\")\n",
    "            # ax[idx,idy].plot([dt_true, dt_true], [-0.1, 1.1], alpha=0.5, linestyle=\":\", color=\"forestgreen\")\n",
    "            # ax[idx,idy].set_ylim([-0.1, 1.1])\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Trajectory\", data=result, step=stepid)\n",
    "\n",
    "    def idToText(self, id):\n",
    "        names = [\"\", \"ysr\", \"rsr\", \"gsr\", \"bsr\", \"psr\", \"ylr\", \"rlr\", \"glr\", \"blr\", \"plr\", \"yss\", \"rss\", \"gss\", \"bss\", \"pss\", \"yls\", \"rls\", \"gls\", \"bls\", \"pls\"]\n",
    "        return names[id]\n",
    "\n",
    "    def plotAttention(self, attention_weights, image_dict, language, stepid):\n",
    "        tf_attention_weights = self.torch2tf(attention_weights)\n",
    "        tf_language = self.torch2tf(language)\n",
    "\n",
    "        tf_attention_weights = tf_attention_weights.numpy()\n",
    "        classes           = image_dict[\"detection_classes\"][0][:len(tf_attention_weights)].numpy().astype(dtype=np.int32)\n",
    "        classes           = [self.idToText(i) for i in classes]\n",
    "        x                 = np.arange(len(tf_attention_weights))\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        plt.bar(x, tf_attention_weights)\n",
    "        plt.xticks(x, classes)\n",
    "        ax.set_ylim([0, 1])\n",
    "        plt.text(0.01, 0.95, self.voice.tokensToSentence(tf_language.numpy().tolist()), horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Attention\", data=result, step=stepid)\n",
    "    \n",
    "    def plotClassAccuracy(self, gt_class, pred_class, pred_class_std, language, stepid):\n",
    "        labels     = [\"ysr\", \"rsr\", \"gsr\", \"bsr\", \"psr\", \"ylr\", \"rlr\", \"glr\", \"blr\", \"plr\", \"yss\", \"rss\", \"gss\", \"bss\", \"pss\", \"yls\", \"rls\", \"gls\", \"bls\", \"pls\"]\n",
    "        tf_gt_class = self.torch2tf(gt_class)\n",
    "        tf_pred_class = self.torch2tf(pred_class)\n",
    "        tf_language = self.torch2tf(language)\n",
    "\n",
    "        \n",
    "        \n",
    "        tf_gt_class   = tf_gt_class.numpy()\n",
    "        tf_pred_class = tf_pred_class.numpy()\n",
    "        x          = np.arange(len(tf_gt_class))\n",
    "        width      = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        #rects1 = ax.bar(x - width/2, gt_class, width, label='GT', color=\"forestgreen\")\n",
    "        #rects2 = ax.bar(x + width/2, pred_class, width, yerr=pred_class_std, label='Pred', color=\"midnightblue\")\n",
    "        ax.set_xticks(x)\n",
    "        # ax.set_xticklabels(labels)\n",
    "        plt.text(0.01, 0.95, self.voice.tokensToSentence(tf_language.numpy().tolist()), horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Attention\", data=result, step=stepid)\n",
    "\n",
    "    def plotDeltaT(self, y_true, y_pred, stepid):\n",
    "        tf_y_true = self.torch2tf(y_true)\n",
    "        tf_y_pred = self.torch2tf(y_pred)\n",
    "\n",
    "        gt = tf_y_true.numpy()\n",
    "        pd = tf_y_pred.numpy()[:,0]\n",
    "        jdata = np.stack((gt,pd), axis=1)\n",
    "        svals = jdata[np.argsort(jdata[:,0]),:]\n",
    "        x     = np.arange(svals.shape[0])\n",
    "        width = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        rects1 = ax.bar(x - width/2, svals[:,0], width, label='GT', color=\"forestgreen\")\n",
    "        rects2 = ax.bar(x + width/2, svals[:,1], width, label='Pred', color=\"midnightblue\")\n",
    "        ax.set_xticks(x)\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"DeltaT\", data=result, step=stepid)\n",
    "\n",
    "    def plotWeights(self, gt_w, pred_w, stepid):\n",
    "        tf_gt_w = self.torch2tf(gt_w)\n",
    "        tf_pred_w = self.torch2tf(pred_w)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2,sharey=True,sharex=True)\n",
    "        # fig.set_size_inches(4, 10)\n",
    "\n",
    "        combined_weights = np.concatenate((tf_gt_w.numpy(), tf_pred_w.numpy()), axis=0).T\n",
    "\n",
    "        ax1.imshow(combined_weights[:,:7], cmap=\"RdBu\")\n",
    "        ax2.imshow(combined_weights[:,7:], cmap=\"RdBu\")\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        plt.close()\n",
    "        with self.__tboard_validation.as_default():\n",
    "            tf.summary.image(\"Weights\", data=result, step=stepid)\n",
    "\n",
    "    def interpolateTrajectory(self, trj, target):\n",
    "        tf_trj = self.torch2tf(trj)\n",
    "        tf_target = self.torch2tf(target)\n",
    "\n",
    "        current_length = tf_trj.shape[0]\n",
    "        dimensions     = tf_trj.shape[1]\n",
    "        result         = np.zeros((tf_target, dimensions), dtype=np.float32)\n",
    "    \n",
    "        for i in range(dimensions):\n",
    "            result[:,i] = np.interp(np.linspace(0.0, 1.0, num=tf_target), np.linspace(0.0, 1.0, num=current_length), trj[:,i])\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def plotDMPTrajectory(self, y_true, y_pred, y_pred_std = None, phase= None, \\\n",
    "        dt= None, p_dt= None, stepid= None, name = \"Trajectory\", save = False, \\\n",
    "            name_plot = None, path=None, tol_neg = None, tol_pos=None, inpt = None, opt_gen_trj=None, window = 0):\n",
    "        tf_y_true = self.torch2tf(y_true)\n",
    "        tf_y_pred = self.torch2tf(y_pred)\n",
    "        tf_phase = self.torch2tf(phase)\n",
    "        tf_inpt = self.torch2tf(inpt)\n",
    "        if p_dt is not None:\n",
    "            tf_dt = self.torch2tf(dt)\n",
    "            tf_p_dt = self.torch2tf(p_dt)\n",
    "        if opt_gen_trj is not None:\n",
    "            tf_opt_gen_trj = self.torch2tf(opt_gen_trj)\n",
    "            tf_opt_gen_trj = tf_opt_gen_trj.numpy()\n",
    "\n",
    "        tf_y_true      = tf_y_true.numpy()\n",
    "        tf_y_pred      = tf_y_pred.numpy()\n",
    "        tf_inpt        = tf_inpt.numpy()\n",
    "        if tf_phase is not None:\n",
    "            tf_phase       = tf_phase.numpy()\n",
    "\n",
    "        if p_dt is not None:\n",
    "            tf_dt          = tf_dt.numpy() * 350.0\n",
    "            tf_p_dt        = tf_p_dt.numpy()\n",
    "        trj_len      = tf_y_true.shape[0]\n",
    "        \n",
    "        #fig, ax = plt.subplots(3,3)\n",
    "        fig, ax = self.fig, self.ax\n",
    "        #fig.set_size_inches(9, 9)\n",
    "        neg_inpt = tf_y_true + tol_neg[None,:].cpu().numpy()\n",
    "        pos_inpt = tf_y_true + tol_pos[None,:].cpu().numpy()\n",
    "        for sp in range(len(tf_y_true[0])):\n",
    "            idx = sp // 3\n",
    "            idy = sp  % 3\n",
    "            ax[idx,idy].clear()\n",
    "\n",
    "            # GT Trajectory:\n",
    "            if tol_neg is not None:\n",
    "\n",
    "                ax[idx,idy].plot(range(tf_y_pred.shape[0]), neg_inpt[:,sp], alpha=0.75, color='orangered')\n",
    "                ax[idx,idy].plot(range(tf_y_pred.shape[0]), pos_inpt[:,sp], alpha=0.75, color='orangered')\n",
    "            ax[idx,idy].plot(range(trj_len), tf_y_true[:,sp],   alpha=1.0, color='forestgreen')            \n",
    "            ax[idx,idy].plot(range(tf_y_pred.shape[0]), tf_y_pred[:,sp], alpha=0.75, color='mediumslateblue')\n",
    "            if opt_gen_trj is not None:\n",
    "                ax[idx,idy].plot(range(tf_y_pred.shape[0]), tf_opt_gen_trj[:,sp], alpha=0.75, color='lightseagreen')\n",
    "                diff_vec = tf_opt_gen_trj - tf_y_pred\n",
    "                ax[idx,idy].plot(range(tf_y_pred.shape[0]), diff_vec[:,sp], alpha=0.75, color='pink')\n",
    "\n",
    "            #ax[idx,idy].errorbar(range(tf_y_pred.shape[0]), tf_y_pred[:,sp], xerr=None, yerr=None, alpha=0.25, fmt='none', color='mediumslateblue')\n",
    "            #ax[idx,idy].set_ylim([-0.1, 1.1])\n",
    "            if p_dt is not None:\n",
    "                ax[idx,idy].plot([tf_dt, tf_dt], [0.0,1.0], linestyle=\":\", color='forestgreen')\n",
    "\n",
    "        if inpt is not None:\n",
    "            ax[-1,-1].clear()\n",
    "            ax[-1,-1].plot(range(inpt.shape[-1]), tf_inpt,   alpha=1.0, color='forestgreen')     \n",
    "        \n",
    "        if tf_phase is not None:\n",
    "            ax[2,2].clear()\n",
    "            ax[2,2].plot(range(tf_y_pred.shape[0]), tf_phase, color='orange')\n",
    "        if p_dt is not None:\n",
    "            ax[2,2].plot([tf_dt, tf_dt], [0.0,1.0], linestyle=\":\", color='forestgreen')\n",
    "            ax[2,2].plot([tf_p_dt*350.0, tf_p_dt*350.0], [0.0,1.0], linestyle=\":\", color='mediumslateblue')\n",
    "            ax[2,2].set_ylim([-0.1, 1.1])\n",
    "\n",
    "        result = np.expand_dims(self.finishFigure(fig), 0)\n",
    "        if save:\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            plt.savefig(path + name_plot + '.png')\n",
    "        #fig.clear()\n",
    "        #plt.close()\n",
    "        if not save:\n",
    "            with self.__tboard_validation.as_default():\n",
    "                tf.summary.image(name, data=result, step=stepid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log dir: /home/hendrik/Documents/master_project/LokalData/test/gboard/BC_PPO/train/\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hashids import Hashids\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tboard = TBoardGraphsTorch(logname='BC_PPO', data_path='/home/hendrik/Documents/master_project/LokalData/test/', prefix='BC ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_trainer = bc.BC(\n",
    "    observation_space=toy_env.observation_space,\n",
    "    action_space=toy_env.action_space,\n",
    "    expert_data=transitions,\n",
    "    optimizer_kwargs={'lr':1e-4}\n",
    ")\n",
    "torch.save(bc_trainer.policy.state_dict(), \"/home/hendrik/Documents/master_project/LokalData/test/bc0.8\")\n",
    "bc_trainer.policy.load_state_dict(torch.load(\"/home/hendrik/Documents/master_project/LokalData/test/bc0.8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log dir: /home/hendrik/Documents/master_project/LokalData/test/gboard/BC_PPO_1e-4/train/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/sb/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BC epoch: 100%|██████████| 20/20 [00:21<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0050)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BC epoch: 100%|██████████| 20/20 [00:23<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BC epoch: 100%|██████████| 20/20 [00:25<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0270)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BC epoch:  65%|██████▌   | 13/20 [00:12<00:04,  1.57it/s]"
     ]
    }
   ],
   "source": [
    "tboard = TBoardGraphsTorch(logname='BC_PPO_1e-4', data_path='/home/hendrik/Documents/master_project/LokalData/test/')\n",
    "for i in range(100):\n",
    "    rew = []\n",
    "    for j in range(1000):\n",
    "        obs = val_env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = bc_trainer.policy.predict(obs)\n",
    "            obs, reward, done, _ = val_env.step(action=action)\n",
    "        rew.append(reward)\n",
    "    reward = torch.tensor(rew).type(torch.float).mean()\n",
    "    print(reward)\n",
    "    tboard.addValidationScalar('success rate', reward.detach(), stepid=i)\n",
    "    target_trj = val_env.label[val_env.current_env]\n",
    "    gen_trj = val_env.traj\n",
    "    inpt = val_env.data[val_env.current_env][0]\n",
    "\n",
    "    tol_neg = -0.55*torch.ones([val_env.traj.size(-1)])\n",
    "    tol_pos = 0.7*torch.ones([val_env.traj.size(-1)])\n",
    "    tboard.plotDMPTrajectory(target_trj, gen_trj, torch.zeros_like(gen_trj),\n",
    "                                None, None, None, stepid=i, save=False, name_plot='imitation baseline', path='',\\\n",
    "                                    tol_neg=tol_neg, tol_pos=tol_pos, inpt = inpt, name='imitation baseline', opt_gen_trj = None, window=None)\n",
    "    bc_trainer.train(n_epochs=20, log_interval=100000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "vec_toy_env = make_vec_env(my_env, n_envs=1)\n",
    "SAMPLED_ENVS = 0\n",
    "STEPS_TAKEN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.save('backup')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.load('backup')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLED_ENVS = 0\n",
    "STEPS_TAKEN = 0\n",
    "rein_model = PPO(\"MlpPolicy\", vec_toy_env, verbose=0, learning_rate=1e-4)\n",
    "rein_model.policy = policy\n",
    "rein_model.policy.to(rein_model.device)\n",
    "\n",
    "for i in range(100):\n",
    "    rein_model.learn(total_timesteps=1000)\n",
    "    print_reward(rein_model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLED_ENVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_TAKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_reward(policy, logname = 'ppo'):\n",
    "    tboard = TBoardGraphsTorch(logname=logname, data_path='/home/hendrik/Documents/master_project/LokalData/stableBaselines/')\n",
    "    rew = []\n",
    "    for j in range(1000):\n",
    "        obs = val_env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = policy.predict(obs)\n",
    "            obs, reward, done, _ = val_env.step(action=action)\n",
    "        rew.append(reward)\n",
    "    reward = torch.tensor(rew).type(torch.float).mean()\n",
    "    print(f'num_envs: {SAMPLED_ENVS}')\n",
    "    print(reward)\n",
    "    tboard.addValidationScalar('success rate', reward.detach(), stepid=i)\n",
    "    target_trj = val_env.label[val_env.current_env]\n",
    "    gen_trj = val_env.traj\n",
    "    inpt = val_env.data[val_env.current_env][0]\n",
    "\n",
    "    tol_neg = -0.55*torch.ones([val_env.traj.size(-1)])\n",
    "    tol_pos = 0.7*torch.ones([val_env.traj.size(-1)])\n",
    "    tboard.plotDMPTrajectory(target_trj, gen_trj, torch.zeros_like(gen_trj),\n",
    "                                None, None, None, stepid=i, save=False, name_plot='ppo fine tuning baseline', path='',\\\n",
    "                                    tol_neg=tol_neg, tol_pos=tol_pos, inpt = inpt, name='ppo fine tuning baseline', opt_gen_trj = None, window=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    rew = []\n",
    "    for j in range(1000):\n",
    "        obs = val_env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = bc_trainer.policy.predict(obs)\n",
    "            obs, reward, done, _ = val_env.step(action=action)\n",
    "        rew.append(reward)\n",
    "    reward = torch.tensor(rew).type(torch.float).mean()\n",
    "    print(reward)\n",
    "    tboard.addValidationScalar('success rate', reward.detach(), stepid=SAMPLED_ENVS)\n",
    "    target_trj = val_env.label[val_env.current_env]\n",
    "    gen_trj = val_env.traj\n",
    "    inpt = val_env.data[val_env.current_env][0]\n",
    "\n",
    "    tol_neg = -0.55*torch.ones([val_env.traj.size(-1)])\n",
    "    tol_pos = 0.7*torch.ones([val_env.traj.size(-1)])\n",
    "    tboard.plotDMPTrajectory(target_trj, gen_trj, torch.zeros_like(gen_trj),\n",
    "                                None, None, None, stepid=i, save=False, name_plot='imitation baseline', path='',\\\n",
    "                                    tol_neg=tol_neg, tol_pos=tol_pos, inpt = inpt, name='imitation baseline', opt_gen_trj = None, window=None)\n",
    "    bc_trainer.train(n_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f3d5eba35af06b53455a28db0e1aae84232e508d0cfb50425799c8ae5a4a11b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('sb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
